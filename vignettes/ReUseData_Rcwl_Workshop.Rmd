---
title: "Use R to Create and Execute Reproducible CWL Workflows for Genomic Research"
author: Qian Liu[qian.liu@roswellpark.org]
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Rcwl_variantCall}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---


```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

# Use R to Create and Execute Reproducible CWL Workflows for Genomic Research

Authors:
	Qian Liu ^[Roswell Park Comprehensive Cancer Center],
    Another Author^[Roswell Park Comprehensive Cancer Center].
    <br/>
Last modified: July 27, 2023.

## Overview

### Pre-requisites

- Basic familiarity with DNA-seq data variant calling 
- Interest of using workflow language 

### Workshop Participation

The workshop format is a 45 minute session consisting of hands-on demos, exercises and Q&A.

### R / Bioconductor packages used
- ReUseData
- RcwlPipelines
- Rcwl


### Description

In this workshop, we will demonstrate how to use `RcwlPipelines` and
`ReUseData` to implement variant calling workflows within R using the
`Mutect2` from GATK. This whole workflow is based on R programming
language and can be deployed in local computer, HPC and cloud
computing platforms, using `docker`, `singularity` or
`udocker`. [FIXME] 

This workshop will be instructor-led live demo with executable code
with real DNA-seq data.  

[DELETE] Along with the topic of your workshop, include
how students can expect to spend their time. For the description may
also include information about what type of workshop it is
(e.g. instructor-led live demo, lab, lecture + lab, etc.). Instructors
are strongly recommended to provide completely worked examples for lab
sessions, and a set of stand-alone notes that can be read and
understood outside of the workshop.

### Pre-requisites

List any workshop prerequisites, for example:

* Basic knowledge of R syntax
* Familiarity with the GenomicRanges class
* Familiarity with xyz vignette (provide link)

List relevant background reading for the workshop, including any
theoretical background you expect students to have.

* List any textbooks, papers, or other reading that students should be
  familiar with. Include direct links where possible.

### Participation

Describe how students will be expected to participate in the workshop.

### _R_ / _Bioconductor_ packages used

```
Rcwl
RcwlPipelines
ReUseData [FIXME: more?]
```
List any _R_ / _Bioconductor_ packages that will be explicitly covered.

### Time outline

An example for a 45-minute workshop:

| Activity                     | Time |
|------------------------------|------|
| Packages                     | 15m  |
| Package Development          | 15m  |
| Contributing to Bioconductor | 5m   |
| Best Practices               | 10m  |

### Workshop goals and objectives

List "big picture" student-centered workshop goals and learning
objectives. Learning goals and objectives are related, but not the
same thing. These goals and objectives will help some people to decide
whether to attend the conference for training purposes, so please make
these as precise and accurate as possible.

*Learning goals* are high-level descriptions of what
participants will learn and be able to do after the workshop is
over. *Learning objectives*, on the other hand, describe in very
specific and measurable terms specific skills or knowledge
attained. The [Bloom's Taxonomy](#bloom) may be a useful framework
for defining and describing your goals and objectives, although there
are others.

### Learning goals

Some examples:

* describe how to...
* identify methods for...
* understand the difference between...

### Learning objectives

* analyze xyz data to produce...
* create xyz plots
* evaluate xyz data for artifacts


## Workshop: Somatic variant calling
## Workshop: downstream: variant annotation/filtering in R

For the somatic variant calling, we will need to prepare the following: 

- Experiment data 
  - In the format of `.bam`, `.bam.bai` files
- ReUsable Genomic data 
  - reference sequence file (`b37` or `hg38`)
  - Panel of Normals (PON) [ref](https://gatk.broadinstitute.org/hc/en-us/articles/360035890631-Panel-of-Normals-PON-)
- Software tool: 
  - Here we use `Mutect2`to Call somatic SNVs and indels via local assembly of
    haplotypes. [ref](https://gatk.broadinstitute.org/hc/en-us/articles/360037593851-Mutect2)

We also want to have the data analysis workflow to be reproducible:  

1. Software tool properly tracked for version, docker image etc.
2. Data provenance properly tracked for public data resources for: 
	- workflow reproducibility
	- later reuse in other similar projects

The first can be solved by workflow languages (e.g., CWL, WDL,
snakemake, etc.). There is no similar tools for the 2nd task. 

In this workshop, I will demostrate two _Bioconductor_ packages:
`Rcwl` as an R interface for `CWL`, and `RcwlPipelines` for >200
pre-built bioinformatics tools and best practice pipelines in _R_,
that are easily usable and highly customizable. I will also introduce
a _R/Bioconductor_ package `ReUseData` for the management of reusable
genomic data.

With these tools, we should be able to conduct reproducible data
analysis using commonly used bioinformatics tools (including
command-line based tools and _R/Bioconductor_ packages) and validated,
best practice workflows (based on workflow languages such as CWL)
within a unified _R_ programming environment.

### Prepare experiment data 

First, we will need to prepare the experiment data. Here we have
prepared a small DNA-seq dataset for demo purposes. We can download
them from the GitHub repository and save to a specific folder.

```{r}
library(ReUseData)
library(RcwlPipelines)
library(Rcwl)
workdir <- "/tmp/Bioc2023_rcwl"
dir.create(workdir)
```

To better manage the experiment data, we can write a data recipe and
add some meta information for them to be easily tracked.

The `recipeMake` function will wrap the command line script for data
downloading/processings into an executable data recipe in R. We will
specify the inputs and outputs of the data recipe and use `outputGlob`
to specify the output pattern (for internal check). 

```{r, eval=TRUE}
script <- '
wget https://github.com/hubentu/somatic-snv-test-data/raw/master/tumor.bam
wget https://github.com/hubentu/somatic-snv-test-data/raw/master/tumor.bam.bai
wget https://github.com/hubentu/somatic-snv-test-data/raw/master/normal.bam
wget https://github.com/hubentu/somatic-snv-test-data/raw/master/normal.bam.bai
'

rcp_expdata <- recipeMake(shscript = script,
                          outputID = "bams",
                          outputGlob = "*.bam*")

## rcp_expdata <- addMeta(
##     cwl = rcp_expdata,
##     label = "somatic snv test data",
##     doc = "test data for somatic variant calling",
##     outputLabels = c("bams"),
##     outputDocs = c("The data is from NA12878 (tumor) and NA12892 (normal) and represents a tiny chunk of chromsome 21. It was created from 1000 Genomes Project."),
##     extensions = list(
##         author = "genome/somatic-snv-test-data",
##         url = "https://github.com/genome/somatic-snv-test-data",
##         date = Sys.Date()))
```

Then we use `getData` function to evaluate the data recipe (normally
we need to first assign values to the input parameters if they exist),
then the data recipe is submitted internally as a cwl task evaluting
the shell script for data downloading/processing. Desired output files
will be generated in the specifiec `outdir`. `notes` can be added for
the dataset for easy query later.

```{r, eval=TRUE}
getData(rcp_expdata, outdir = file.path(workdir, "data"),
        notes = c("somatic snv", "tumor normal bams"),
        showLog=TRUE)
```
We can see the files are successfully downloaded.

```{r}
list.files(file.path(workdir, "data"), pattern = "*.bam*")  ## desired experiment data
```


Accompanying with the desired datasets, we can also see some files
with extensions of `md5`, `cwl`, `yml` and `sh`. These files are
automatically generated by the function `getData`, where the the meta
information for data recipe are recorded.

```{r}
list.files(file.path(workdir, "data"), pattern = "rcp_expdata")  ## meta files
```

By default, the meta file names for these meta files are paste of
recipe name, and input parameter values separated by `_`. This can be
changed by the `prefix` argument if needed. 

- `[recipeName_params].cwl`: Rcwl object defined in `Rcwl` for
  tool or data recipe.
- `[recipeName_params].yml`: File containing values for input
parameters for both tool and data recipes through recipe evaluation
functions (e.g., `runCWL`, `getData`). For data recipes, it includes
additional meta information for the output files, notes, and date, etc
for data tracking purposes, which are added by `getData` function.
- `[recipeName_params].sh`: The command lines in a shell script. 
- `[recipeName_params].md5`: unique identifier for each dataset.

### Data use

Then we use `dataUpdate` to cache the data in specified data directory
`dir`. The data can be easily tracked and searched using `dataSearch`
function. Meta information about the data, such as file paths, can be
easily retrieved for later use.

```{r}
dataUpdate(dir = workdir)
ds1 <- dataSearch(c("bam"))
dataPaths(ds1)
```

### Load public genomic data 

Get shared genomic data for mutect2.

#### Panel of normal vcf

```{r}
## library(ReUseData)
recipeUpdate()
```

```{r}
recipeSearch("mutect2")
rcp <- recipeLoad("gcp_gatk_mutect2_b37")

## get panel of normal vcf
rcp$filename <- "Mutect2-exome-panel.vcf"
rcp$idx <- "idx"
getData(rcp, outdir = file.path(workdir, "shareData"),
        notes = c("mutect2", "panel of normal"),
        showLog = TRUE)
```

Here Let's check the output directory for the files. 

- Downloaded genomic file dataset. 
- meta files. 

```{r}
## check output
dir(file.path(workdir, "shareData"))
```

#### Reference genome

```{r, eval=FALSE}
rcp$filename <- "Homo_sapiens_assembly19.fasta"
rcp$idx = "fai"
getData(rcp, outdir = file.path(workdir, "shareData"),
        notes = c("human", "reference genome", "hg19", "b37"),
        showLog = TRUE)

rcp$filename <- "Homo_sapiens_assembly19.dict"
rcp$idx <- ""
getData(rcp, outdir = file.path(workdir, "shareData"),
        notes = c("human", "reference genome dict", "hg19", "b37"),
        showLog = TRUE)
## check output
dir(file.path(workdir, "shareData"))
```

* Update load data

`dataUpdate` will manage the data downloaded so that the data can be
managed and easily searched by `dataSearch` with other convenient
utility fuctions.

```{r, eval=FALSE}
dataUpdate(dir = workdir, keepTags=FALSE, cleanup = TRUE)
rs1 <- dataSearch("mutect2")
rs2 <- dataSearch("reference")
```

Data can be easily tagged e.g., with a specific software name, so that
it can be retrieved easily after with that keyword using `dataSearch`.

```{r, eval=FALSE}
dataTags(rs2[2]) <- "mutect2"
rs <- dataSearch("mutect2")

dataNames(rs)
dataNotes(rs)
dataParams(rs)
dataTags(rs)

ref <- dataPaths(rs)[1]
pon <- dataPaths(rs[2])
```


### Run  `mutect2` pipeline in R 

#### Load pipeline or tools 

```{r, eval=FALSE}
library(RcwlPipelines)
cwlUpdate()
```

```{r, eval=FALSE}
cwlSearch("mutect2")
mutect2pl <- cwlLoad("pl_Mutect2PL")
plotCWL(mutect2pl)

## run simple tool instead of pipeline because of large files
mutect2 <- cwlLoad("tl_Mutect2")

## change to smaller docker image
ds <- searchContainer("gatk4")
req1 <- requireDocker(ds[1, "container"])
requirements(mutect2)[[1]] <- req1
```

```{r, eval=FALSE}
## check inputs
inputs(mutect2)

## prepare capture region
write.table(rbind(c(21, 10400000, 10500000)), file.path(workdir, "region.bed"),
            row.names=FALSE, col.names = FALSE, quote=FALSE, sep="\t")

## assign inputs
mutect2$tbam <- file.path(workdir, "data/tumor.bam")
mutect2$nbam <- file.path(workdir, "data/normal.bam")
mutect2$normal <- "NA12892"
mutect2$Ref <- ref
mutect2$pon <- pon
mutect2$interval <- file.path(workdir, "region.bed")
mutect2$out <- "somatic.vcf"
```

```{r, eval=FALSE}
## run tool
runCWL(mutect2, outdir = file.path(workdir, "output"), docker = "udocker", showLog = TRUE)
```

```{r, eval=FALSE}
## checkout pipeline results
list.files(file.path(workdir, "output"))
```
