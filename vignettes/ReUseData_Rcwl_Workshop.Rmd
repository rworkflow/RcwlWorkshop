---
title: "Use R to Create and Execute Reproducible CWL Workflows for Genomic Research"
author:
  - Qian Liu ^[Roswell Park Comprehensive Cancer Center, Qian.Liu@RoswellPark.org]
  - Qiang Hu ^[Roswell Park Comprehensive Cancer Center]
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Rcwl_variantCall}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  package.startup.message = FALSE,
  rmarkdown.html_vignette.check_title = FALSE,
  eval=FALSE)
```

## Overview

### Pre-requisites

- Basic familiarity with variant calling in DNA-seq data
- Interest of using workflow language 

### Workshop Participation

The workshop format is a 45 minute session consisting of hands-on demos and Q&A.

### R / Bioconductor packages used
- RcwlPipelines
- Rcwl
- ReUseData
- VariantAnnotation

### Description

In this workshop, we will demonstrate three _Bioconductor_ packages:
`Rcwl` as an R interface for `CWL`; `RcwlPipelines` with >200
pre-built bioinformatics tools and best practice pipelines in _R_,
that are easily usable and highly customizable; and `ReUseData` for
the management of reusable genomic data.

This workshop will implement variant calling workflows within R using the
`Mutect2` from GATK. This whole workflow is based on R programming
language and can be deployed in local computer, HPC and cloud
computing platforms, using `docker`, `singularity` or
`udocker`.

With these tools, we should be able to conduct reproducible data
analysis using commonly used bioinformatics tools (including
command-line based tools and _R/Bioconductor_ packages) and validated,
best practice workflows (based on workflow languages such as CWL)
within a unified _R_ programming environment.

## Workshop: Somatic variant calling

For the somatic variant calling, we will need to prepare the following: 

- Experiment data 
  - In the format of `.bam`, `.bam.bai` files
- ReUsable Genomic data 
  - reference sequence file (`b37` or `hg38`)
  - Panel of Normals [PON](https://gatk.broadinstitute.org/hc/en-us/articles/360035890631-Panel-of-Normals-PON-)
- Software tool: 
  - Here we use
    [Mutect2](https://gatk.broadinstitute.org/hc/en-us/articles/360037593851-Mutect2)
    to Call somatic SNVs and indels via local assembly of haplotypes.

There will be three ways to do the analysis task. 

1. Command-line interface. We can install the software and write shell scripts. 

2. Workflow language. We can use workflow language (e.g., CWL, WDL,
   nextflow, snakemake) to streamline the workflow of data analysis,
   using containerized tools (no software installation, version
   tracking, etc.)

   - More efficient (especially if multiple tools are included)
   - REPRODUCIBLE!
   - Need to install a workflow runner (e.g., cwltool,
     arvados-cwl-runner)
   - Learning curve

3. `Rcwl/RcwlPipelines`. Write/use CWL-based data analysis tools/workflows within
   _R_ programming language 
   
   - All benefits of workflow language (efficient, reproducible)
   - No workflow runner needed
   - Can wrap both command-line tools and _R/Bioconductor_ package
     functions (connecting upstream data processing and downstream
     data analysis).
   - unified R programming environment
   
   `ReUseData`: Reproducible and reusable genomic data management.

	- Public genomic data resources can be easily managed and reused
     in different projects.


### Prepare the software tools in _R_ using `RcwlPipelines` 

`RcwlPipelines` includes more than 200 pre-built, commonly used
bioinformatics tools, such as `BWA` for DNA read alignment, `STAR` for
RNA read quantification, `Mutect2` for somatic variant calling. Here
we use `Mutect2` to demonstrate the use of these tools to run
CWL-based data analysis workflow within _R_.

Below we will show 3 core functions: `cwlUpdate`, `cwlSearch` and
`cwlLoad` to update, search and load the needed tool or pipeline in
_R_.

#### Load tool or pipeline

The `cwlUpdate` function syncs the current `Rcwl` tool recipes in the
local cache. It returns a `cwlHub` object that contains the most
updated `Rcwl` recipes. User need to call this function for first-time
use or if they want to use a newly added tool/pipeline from
`RcwlPipelines`.

```{r, message=FALSE}
library(RcwlPipelines)
library(Rcwl)
devtools::load_all()
workdir <- "rcwl_demo"
dir.create(workdir)
```

Then the existing tool recipes can be queried using with `cwlSearch`
with multiple keywords. Then it's ready to be loaded into _R_ with
`cwlLoad`.

Multiple tool/recipes are available with `Mutect2`. For example,
`pl_Mutect2PL` includes multiple tools for the tasks of variant
calling, QC, and filtering
<https://rcwl.org/RcwlRecipes/Mutect2PL.html>, where `Mutect2` is part
of the pipeline.

```{r}
cwlUpdate()
cwlSearch("mutect2")
mutect2pl <- cwlLoad("pl_Mutect2PL")
plotCWL(mutect2pl)
```

In this workshop, we will use the simple tool of `tl_Mutect2` for
variant calling only. We can customize the tools by using a smaller
docker image for demo purposes. 

```{r}
mutect2 <- cwlLoad("tl_Mutect2")
## the official GATK docker image
requirements(mutect2)[[1]]  
## change to smaller BioConda docker image
ds <- searchContainer("gatk4")
req1 <- requireDocker(ds[1, "container"])
requirements(mutect2)[[1]] <- req1
requirements(mutect2)[[1]]
```

#### Check data inputs 

We can use the `Rcwl::inputs` function to check the required input
parameters for the tool. For `Mutect2`, multiple parameters are
defined to map to the tool arguments. Major inputs would be the BAM
files containing reads (`tbam` and `nbam` for tumor and normal
separately), the reference sequence file (`Ref`), and the `pon` for
panel of normals VCF files. 

Some input parameters come with default values (such as `f1r2`, which
can be changed easily. More details about the tool arguments can be
found
[here](https://gatk.broadinstitute.org/hc/en-us/articles/360037593851-Mutect2).

```{r}
inputs(mutect2)
```

We will assign values to the input parameters before evaluation. 

For the experiment data, we have prepared a small DNA-seq dataset for
demo purposes. 

For the public genomic data resources that are needed to run `mutect2`
for somatic variant calling: the reference sequence file (`Ref`) and
PON VCF file (`pon`), we can assign the file path directly to the
corresponding parameters if you already have them, and evaluate the
data recipe now with `runCWL` function.

However, as these genomic data files can be repeatedly used in many
different projects (e.g., DNA-seq data), we propose an
_R/Bioconductor_ package `ReUseData` to manage these files so that
they can be easily tracked for tool/data provenance to safely
reproduce and reuse.

```{r}
mutect2$tbam <- system.file("extdata/tumor.bam", package="RcwlWorkshop")
mutect2$nbam <- system.file("extdata/normal.bam", package="RcwlWorkshop")
mutect2$normal <- "NA12892"
mutect2$out <- "somatic.vcf"
## prepare capture region
write.table(rbind(c(21, 10400000, 10500000)), file.path(workdir, "region.bed"),
            row.names=FALSE, col.names = FALSE, quote=FALSE, sep="\t")
mutect2$interval <- file.path(workdir, "region.bed")
inputs(mutect2)
## mutect2$Ref <-
## mutect2$pon <-
## runCWL(mutect2, outdir = file.path(workdir, "output"), docker = "udocker", showLog = TRUE)
```

### Prepare the public genomic data resources using `ReUseData`

`ReUseData` facilitates transformation of shell scripts for data
preprocessing (e.g., downloading, indexing) into workflow-based data
recipes. Evaluation of data recipes generate curated data files in
their generic formats (e.g., VCF, bed) with automatically generated
meta files, this will help track data and tool provenance for
subsequent data reuse.

We have pre-built some data recipes ([GitHub
repository](https://github.com/rworkflow/ReUseDataRecipe)) which are
ready to be queried and userd directly. They mainly serves as template
for users to write their own. 

The most common case is that a data recipe can manage multiple data
resources with different input parameters (species, versions,
etc.). For example, the `gencode_transcripts` recipe download from
GENCODE, unzip and index the transcript fasta file for human or mouse
with different versions. A simple data downloading (using `wget`) for
a specific file can be written as a data recipe without any input
parameter. For example, The pre-built recipes of
`gcp_gatk_mutect2_b37` and `gcp_gatk_mutect2_hg38` are for the
downloading of genomic data resources from the GATK resource bundle on
[Google Cloud
Bucket](https://console.cloud.google.com/storage/browser/gatk-best-practices/somatic-b37)
based on reference build of `b37` and `hg38` separately. See more
details
[here](https://gatk.broadinstitute.org/hc/en-us/articles/360035890811-Resource-bundle).

In this workshop, we will use the `gcp_gatk_mutect2_b37` data recipe
to download necessary genomic data files for the somatic variant
calling.

#### Data recipes 

We use 4 core functions to update (`recipeUpdate`), search
(`recipeSearch`), load (`recipeLoad`) the data recipe, assign values
to the input parameters (`filename` and `idx`), and then evaluate the
recipe (`getData`) to download the data to your local machine with
automatic tracking and user-specified notes/keywords.

The `getData` function evaluates the data recipe and generate the
desired data output in a user-specified `outdir`. Arbitrary `notes`
can be added for the dataset for easy query later.

Internally, the data recipe is submitted as a cwl task evaluting the
shell script for data downloading/processing.

```{r, message=FALSE}
library(ReUseData)
```

```{r}
recipeUpdate()
recipeSearch("mutect2")
rcp <- recipeLoad("gcp_gatk_mutect2_b37")

## get panel of normal vcf
rcp$filename <- "Mutect2-exome-panel.vcf"
rcp$idx <- "idx"
getData(rcp, outdir = file.path(workdir, "shareData"),
        notes = c("mutect2", "panel of normal"),
        showLog = TRUE)

## check output
list.files(file.path(workdir, "shareData"), pattern= c("panel", "normal"))
```

The output directory includes the downloaded genomic file dataset, as
well as some automatically generated meta files (ending with `md5`,
`cwl`, `yml` and `sh`) by `getData`, where the the meta information
for data recipe are recorded for subsequent reuse. More details about
these meta files, please see the `For developers` section below.

Similarly, we will download the reference genome files using the same
data recipe:

```{r}
## Reference genome files
rcp$filename <- "Homo_sapiens_assembly19.fasta"
rcp$idx = "fai"
getData(rcp, outdir = file.path(workdir, "shareData"),
        notes = c("human", "reference genome", "hg19", "b37"),
        showLog = TRUE)

rcp$filename <- "Homo_sapiens_assembly19.dict"
rcp$idx <- ""
getData(rcp, outdir = file.path(workdir, "shareData"),
        notes = c("human", "reference genome dict", "hg19", "b37"),
        showLog = TRUE)
## check output
list.files(file.path(workdir, "shareData"), pattern = c("assembly19"))
```

Now we have all the data needed. Here we show some utility functions
to manage, query, and use the data.

#### Data management

There are 2 core functions to manage the data locally for easy query
and use.

- `dataUpdate`: Cache the data in specified data directory `dir`
  (works recursively). Need to call for first-time use or if any new
  datasets are generated locally with `getData`.
- `dataSearch`: Query of cached datasets with (multiple) keyword(s)
  (can be keywords from the file name or the user-specified `notes`.

```{r}
dataUpdate(dir = workdir, keepTags=FALSE, cleanup = TRUE)
rs1 <- dataSearch("mutect2")
rs2 <- dataSearch("reference")
```

Besides the `notes` added in `getData`, users can further tag the
data. For example, if a set of datasets can be used as inputs for a
specific software tool, we'll tag these datasets with the software
name, so that they can be retrieved easily with that keyword in
`dataSearch`.

Here we'll tag the reference genome data with `mutect2`, and use some
utility functions to retrieve specific information about the
data. Data path can be retrieved using `dataPaths` function, which
will be passed directly to the `Rcwl` tool recipe for reproducible
data analysis in _R_.
 
```{r}
dataTags(rs2[2]) <- "mutect2"
rs <- dataSearch("mutect2")
rs
ref <- dataPaths(rs)[1]
pon <- dataPaths(rs[2])
## try: dataNames, dataYml, dataNotes, dataParams, etc.
```

### Run reproducible data analysis in _R_

Coming back to the `RcwlPipelines` tool recipe, here we will assign
values to the tool for the reusable genomic data resources that are
managed by `ReUseData`, and evaluate the tool (internally submit the
CWL task) using `runCWL` for reproducible data analysis in _R_.

```{r}
## check inputs
inputs(mutect2)
## assign inputs of reusable genomic data
mutect2$Ref <- ref
mutect2$pon <- pon
inputs(mutect2)
runCWL(mutect2, outdir = file.path(workdir, "output"),
       docker = "udocker", showLog = TRUE)
```

The results should be successfully generated in the user-specified
output directory. The `somatic.vcf` contains all the somatic variants
that are called from the input bam files using the bioinformatics
software tool `Mutect2`.

```{r}
## checkout results
list.files(file.path(workdir, "output"))
```

### Data use 

#### In _R/Bioconductor_ packages for downstream data analysis 

The workflow/tool result files can be conveniently passed to the
downstream _R/Bioconductor_ packages for a unified _R_ programming
environment.

```{r, message=FALSE}
library(VariantAnnotation)
fl <- file.path(workdir, "output/somatic.vcf")
readVcf(fl)
```

#### In workflow language scripts 

Data (output of `dataSearch`) can also be prepared in standard input
formats (`toList`), e.g., YAML and JSON, to be easily integrated in
workflow methods that are locally or cloud-hosted.

Edits may need for the "key" of data value for different workflow
scripts. 

```{r}
dataUpdate(dir = workdir)
ds_mutect2 <- dataSearch("mutect2")
toList(ds_mutect2, format = "json", file=file.path(workdir, "data.json"))
```


### For developers

#### Data annotation files

By evaluating a `ReUseData` data recipe with `getData`, some meta
files for the data will be automatically generated for data and tool
provenance.


By default, the meta file names for these meta files are paste of
recipe name, and input parameter values separated by `_`, which can be
changed by the `prefix` argument in `getData` function if needed.

```{r}
list.files(file.path(workdir, "shareData"),
           pattern = "gcp_gatk_mutect2_b37_Mutect2-exome-panel.vcf_idx")  ## meta files
)```

- `[recipeName_params].cwl`: Rcwl object defined in `Rcwl` for
  tool or data recipe.
- `[recipeName_params].yml`: File containing values for input
parameters for both tool and data recipes through recipe evaluation
functions (e.g., `runCWL`, `getData`). For data recipes, it includes
additional meta information for the output files, notes, and date, etc
for data tracking purposes, which are added by `getData` function.
- `[recipeName_params].sh`: The command lines in a shell script. 
- `[recipeName_params].md5`: unique identifier for each dataset.


#### Create data recipe

Here we use a simple example to show how to create a data recipe. This
recipe will do a simple task of just downloading specific files from
fixed web source without any input parameter.

```{r}
## library(ReUseData)
```

The `recipeMake` function will wrap the command line script for data
downloading/processings into an executable data recipe in R. We will
specify the inputs and outputs of the data recipe and use `outputGlob`
to specify the output pattern (for internal check). 

```{r}
script <- '
wget https://github.com/hubentu/somatic-snv-test-data/raw/master/tumor.bam
wget https://github.com/hubentu/somatic-snv-test-data/raw/master/tumor.bam.bai
wget https://github.com/hubentu/somatic-snv-test-data/raw/master/normal.bam
wget https://github.com/hubentu/somatic-snv-test-data/raw/master/normal.bam.bai
'
rcp_expdata <- recipeMake(shscript = script,
                          outputID = "bams",
                          outputGlob = "*.bam*")
```

We need to assign values to the input parameters if they exist (data
inputs for the shell script). Then the data recipe is ready for the
evaluation using `getData` function (see the `ReUseData` section
above).

#### Create tool/workflow recipes 

For developers who are interested in building their own `Rcwl` tool or
pipeline, we have these functions: 

- Basic functions 

	- `InputParam()`
	- `OutputParam()`
	- `cwlProcess()`
	- `cwlWorkflow()`
	- `cwlStep()`
	
- Advanced functions

	- `arguments()`
	- `requirements()`

Some additional resources: 

[Rcwl vignette](https://www.bioconductor.org/packages/release/bioc/vignettes/Rcwl/inst/doc/Rcwl.html)
[RcwlPipelines recipes](https://github.com/rworkflow/RcwlRecipes/tree/master/Rcwl)
[Tutorial ebook](https://rcwl.org/RcwlBook/)


```{r}
## library(Rcwl)
```




